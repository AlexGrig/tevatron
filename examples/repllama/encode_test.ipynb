{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from contextlib import nullcontext\n",
    "import dataclasses\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModel\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    ")\n",
    "\n",
    "from tevatron.arguments import ModelArguments, DataArguments, \\\n",
    "    TevatronTrainingArguments as TrainingArguments\n",
    "from data import HFQueryDataset, HFCorpusDataset\n",
    "\n",
    "from repllama import RepLLaMA\n",
    "from data import EncodeDataset, EncodeCollator\n",
    "from utils import replace_with_xformers_attention\n",
    "\n",
    "#pd.set_option('display.max_columns', 70)\n",
    "#pd.set_option('display.max_rows', 120)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HfArgumentParser((ModelArguments, DataArguments, TrainingArguments))\n",
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    #model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "    model_args, data_args, training_args = parser.parse_json_file(json_file='./train_params.json')\n",
    "else:\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
    "    model_args: ModelArguments\n",
    "    data_args: DataArguments\n",
    "    training_args: TrainingArguments\n",
    "\n",
    "if training_args.local_rank > 0 or training_args.n_gpu > 1:\n",
    "    raise NotImplementedError('Multi-GPU encoding is not supported.')\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir, token='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'\n",
    "    )\n",
    "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dir': None,\n",
       " 'dataset_name': 'Tevatron/msmarco-passage',\n",
       " 'passage_field_separator': ' ',\n",
       " 'dataset_proc_num': 32,\n",
       " 'train_n_passages': 16,\n",
       " 'positive_passage_no_shuffle': False,\n",
       " 'negative_passage_no_shuffle': False,\n",
       " 'encode_in_path': None,\n",
       " 'encoded_save_path': None,\n",
       " 'encode_is_qry': False,\n",
       " 'encode_num_shard': 1,\n",
       " 'encode_shard_index': 0,\n",
       " 'q_max_len': 32,\n",
       " 'p_max_len': 196,\n",
       " 'data_cache_dir': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataclasses.asdict(data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/data/miniconda3/envs/train_emb3/lib/python3.11/site-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "Using the latest cached version of the module from /home/azureuser/.cache/huggingface/modules/datasets_modules/datasets/Tevatron--beir-corpus/02e1318cd9412cdf85d3f039bf36bec0af49ddeeab2279d4cf19fe556af6f29a (last modified on Wed Mar 13 12:48:30 2024) since it couldn't be found locally at Tevatron/beir-corpus, or remotely on the Hugging Face Hub.\n",
      "03/14/2024 11:51:06 - WARNING - datasets.load -   Using the latest cached version of the module from /home/azureuser/.cache/huggingface/modules/datasets_modules/datasets/Tevatron--beir-corpus/02e1318cd9412cdf85d3f039bf36bec0af49ddeeab2279d4cf19fe556af6f29a (last modified on Wed Mar 13 12:48:30 2024) since it couldn't be found locally at Tevatron/beir-corpus, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "text_max_length = data_args.q_max_len if data_args.encode_is_qry else data_args.p_max_len\n",
    "if data_args.encode_is_qry:\n",
    "    encode_dataset = HFQueryDataset(tokenizer=tokenizer, data_args=data_args,\n",
    "                                    cache_dir=data_args.data_cache_dir or model_args.cache_dir)\n",
    "else:\n",
    "    encode_dataset = HFCorpusDataset(tokenizer=tokenizer, data_args=data_args,\n",
    "                                        cache_dir=data_args.data_cache_dir or model_args.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docid': '4983',\n",
       " 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.',\n",
       " 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_dataset.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_dataset = EncodeDataset(encode_dataset.process(data_args.encode_num_shard, data_args.encode_shard_index),\n",
    "                                   tokenizer, max_len=text_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('4983',\n",
       " {'input_ids': [1, 13382, 29901, 20140, 4984, 3631, 5849, 310, 5199, 716, 4939, 274, 406, 1182, 284, 4796, 4383, 1223, 11517, 297, 325, 4243, 491, 23253, 12489, 15611, 27396, 749, 6382, 292, 29889, 20561, 800, 310, 278, 11258, 310, 274, 406, 1182, 284, 4796, 4383, 297, 278, 14338, 5199, 17294, 508, 6602, 13979, 936, 5849, 322, 1121, 297, 13303, 766, 11614, 29889, 319, 1196, 12812, 23253, 29899, 7915, 287, 15611, 27396, 749, 6382, 292, 313, 29924, 3960, 29897, 5665, 411, 23253, 12489, 7418, 471, 7436, 304, 5645, 278, 20295, 23253, 10825, 29892, 304, 8147, 6198, 385, 275, 327, 14441, 29892, 322, 304, 628, 457, 403, 2211, 29899, 12531, 5713, 495, 11258, 297, 274, 406, 1182, 284, 4796, 4383, 297, 758, 8489, 313, 29876, 353, 29871, 29896, 29955, 29897, 322, 2989, 29899, 8489, 3041, 1934, 313, 29876, 353, 29871, 29955, 467, 1763, 24809, 9545, 310, 5188, 1337, 537, 373, 274, 406, 1182, 284, 4796, 4383, 5849, 29892, 4688, 7737, 362, 758, 8489, 3041, 1934, 313, 29876, 353, 29871, 29896, 29900, 29897, 892, 12399, 263, 1473, 931, 472, 1840, 29889, 512, 278, 6555, 4796, 4383, 278, 2099, 20295, 23253, 10825, 472, 29871, 29906, 29947, 281, 29895, 471, 1880, 29892, 29871, 29896, 29889, 29947, 20710, 456, 29906, 29914, 1516, 29892, 322, 9263, 1463, 11183, 1840, 304, 29871, 29896, 29889, 29906, 20710, 456, 29906, 29914, 1516, 29889, 512, 278, 13446, 2485, 29890, 310, 278, 7463, 26091, 1297, 29892, 278, 2099, 20295, 23253, 16127, 472, 1716, 3064, 892, 2788, 313, 29896, 29889, 29906, 23797, 29871, 29896, 29889, 29896, 20710, 456, 29906, 29914, 1516, 467, 6376, 1230, 385, 275, 327, 14441, 471, 6133, 278, 17649, 12060, 471, 304, 1840, 411, 7621, 8380, 1819, 297, 278, 7463, 26091, 1297, 1135, 297, 278, 6555, 4796, 4383, 29889, 4721, 8489, 3041, 1934, 472, 1840, 10018, 6133, 2099, 23253, 16127, 297, 278, 6555, 4796, 4383, 313, 29896, 29889, 29946, 718, 24028, 29871, 29900, 29889, 29906, 29946, 23797, 29871, 29896, 29889, 29896, 29945, 718, 24028, 29871, 29900, 29889, 29900, 29929, 20710, 456, 29906, 29914, 1516, 29892, 282, 353, 29871, 29900, 29889, 29900, 29896, 29953, 29897, 322, 5224, 6198, 385, 275, 327, 14441, 297, 1716, 10161, 9401, 411, 2989, 29899, 8489, 3041, 1934, 313, 10921, 4383, 29892, 29871, 29896, 29900, 29889, 29929, 718, 24028, 29871, 29900, 29889, 29953, 23797, 29871, 29906, 29906, 29889, 29929, 718, 24028, 29871, 29941, 29889, 29900, 13667, 282, 353, 29871, 29900, 29889, 29900, 29900, 29896, 29936, 7463, 26091, 1297, 29892, 29871, 29906, 29946, 29889, 29900, 718, 24028, 29871, 29946, 29889, 29946, 29946, 23797, 29871, 29941, 29941, 29889, 29896, 718, 24028, 29871, 29900, 29889, 29953, 29995, 282, 353, 29871, 29900, 29889, 29900, 29900, 29953, 467, 10050, 1357, 24446, 630, 18755, 414, 297, 278, 1034, 13364, 1246, 359, 398, 892, 7962, 491, 23253, 12489, 341, 3960, 408, 4688, 408, 29871, 29906, 29947, 281, 29895, 29936, 2989, 29899, 8489, 322, 758, 8489, 3041, 1934, 472, 1840, 10018, 10902, 12651, 297, 4796, 4383, 5713, 495, 13013, 29889, 450, 848, 12266, 393, 4323, 23378, 24809, 358, 310, 4094, 23253, 491, 23253, 12489, 341, 3960, 8128, 25483, 964, 9200, 4984, 3631, 5849, 297, 274, 406, 1182, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encode_dataset[0][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_loader = DataLoader(\n",
    "        encode_dataset,\n",
    "        batch_size=training_args.per_device_eval_batch_size,\n",
    "        collate_fn=EncodeCollator(\n",
    "            tokenizer,\n",
    "            max_length=text_max_length,\n",
    "            padding='max_length'\n",
    "        ),\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        num_workers=training_args.dataloader_num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:32<00:00, 46.05s/it]\n"
     ]
    }
   ],
   "source": [
    "model = RepLLaMA.load(\n",
    "        model_name_or_path=model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepLLaMA(\n",
       "  (lm_q): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_p): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (cross_entropy): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = []\n",
    "lookup_indices = []\n",
    "model = model.to(training_args.device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [33:31<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "for (batch_ids, batch) in tqdm(encode_loader):\n",
    "        lookup_indices.extend(batch_ids)\n",
    "        with torch.cuda.amp.autocast() if training_args.fp16 else nullcontext():\n",
    "            with torch.no_grad():\n",
    "                for k, v in batch.items():\n",
    "                    batch[k] = v.to(training_args.device)\n",
    "                if data_args.encode_is_qry:\n",
    "                    model_output = model(query=batch)\n",
    "                    encoded.append(model_output.q_reps.cpu().detach().numpy())\n",
    "                else:\n",
    "                    model_output = model(passage=batch)\n",
    "                    encoded.append(model_output.p_reps.cpu().detach().numpy())\n",
    "\n",
    "encoded = np.concatenate(encoded)\n",
    "\n",
    "with open(data_args.encoded_save_path, 'wb') as f:\n",
    "    pickle.dump((encoded, lookup_indices), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Llama-2-7b-hf\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 4096,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.37.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'bias',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'in_features',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'out_features',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.lm_p.layers[0].self_attn.q_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_p.layers[0].self_attn.q_proj.state_dict()['weight'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
