{
"output_dir":"repllama_test",
"model_name_or_path": "meta-llama/Llama-2-7b-hf",
"save_steps": 200,
"dataset_name": "Tevatron/msmarco-passage",
"bf16": true,
"tf32":false,
"per_device_train_batch_size": 1,
"gradient_accumulation_steps": 1,
"gradient_checkpointing": false,
"per_device_eval_batch_size": 32,
"train_n_passages": 16,
"learning_rate": 1e-4,
"q_max_len": 32, 
"p_max_len": 196,
"num_train_epochs": 1,
"logging_steps": 10,
"overwrite_output_dir": true,
"dataloader_num_workers": 20,
"negatives_x_device": true,
"warmup_steps": 10,
"include_tokens_per_second": false,
"include_num_input_tokens_seen": false
}
